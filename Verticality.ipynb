{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b6cc8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import laspy\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from scipy.sparse.linalg import lsqr\n",
    "from scipy.interpolate import griddata\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.optimize import least_squares\n",
    "from scipy.spatial import cKDTree as KDTree\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c96a4639",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_File = \"M:\\\\lidar\\\\digi_twin\\\\test\\\\check_neighbor.laz\"\n",
    "input_Data = laspy.read(input_File)\n",
    "inPoints = np.vstack((input_Data.x, input_Data.y, input_Data.z)).T\n",
    "neighborhood_radius = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "223e0876",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lidar_function import calculate_planarity, calculate_verticality, calculate_sphericity, calculate_anisotropy, calculate_surface_variation\n",
    "from lidar_function import calculate_curvature, calculate_omnivariance, calculate_linearity\n",
    "from multiprocessing import Process, Queue\n",
    "\n",
    "\n",
    "def setpriority(pid=None,priority=1):\n",
    "    \"\"\" Set The Priority of a Windows Process.  Priority is a value between 0-5 where\n",
    "        2 is normal priority.  Default sets the priority of the current\n",
    "        python process but can take any valid process ID. \"\"\"\n",
    "        \n",
    "    import win32api,win32process,win32con\n",
    "    \n",
    "    priorityclasses = [win32process.IDLE_PRIORITY_CLASS,\n",
    "                       win32process.BELOW_NORMAL_PRIORITY_CLASS,\n",
    "                       win32process.NORMAL_PRIORITY_CLASS,\n",
    "                       win32process.ABOVE_NORMAL_PRIORITY_CLASS,\n",
    "                       win32process.HIGH_PRIORITY_CLASS,\n",
    "                       win32process.REALTIME_PRIORITY_CLASS]\n",
    "    if pid == None:\n",
    "        pid = win32api.GetCurrentProcessId()\n",
    "    handle = win32api.OpenProcess(win32con.PROCESS_ALL_ACCESS, True, pid)\n",
    "    win32process.SetPriorityClass(handle, priorityclasses[priority])\n",
    "     \n",
    "if __name__ == \"__main__\":\n",
    "    p = os.getpid()\n",
    "    setpriority(p, 1)\n",
    "\n",
    "    planarity_queue = Queue()\n",
    "    planarity_values = Process(target=calculate_planarity, args=(inPoints, 1, planarity_queue, tree,))\n",
    "    planarity_values.start()\n",
    "\n",
    "    planarity_queue3 = Queue()\n",
    "    planarity_values3 = Process(target=calculate_planarity, args=(inPoints, 3, planarity_queue3, tree,))\n",
    "    planarity_values3.start()\n",
    "\n",
    "    planarity_queue10 = Queue()\n",
    "    planarity_values10 = Process(target=calculate_planarity, args=(inPoints, 10, planarity_queue10, tree,))\n",
    "    planarity_values10.start()\n",
    "\n",
    "    verticality_queue = Queue()\n",
    "    verticality_values = Process(target=calculate_verticality, args=(inPoints,1, verticality_queue, tree,))\n",
    "    verticality_values.start()\n",
    "\n",
    "    verticality_queue3 = Queue()\n",
    "    verticality_values3 = Process(target=calculate_verticality, args=(inPoints, 3, verticality_queue3, tree,))\n",
    "    verticality_values3.start()\n",
    "\n",
    "    verticality_queue10 = Queue()\n",
    "    verticality_values10 = Process(target=calculate_verticality, args=(inPoints, 10, verticality_queue10, tree,))\n",
    "    verticality_values10.start()\n",
    "\n",
    "    sphericity_queue = Queue()\n",
    "    sphericity_values = Process(target=calculate_sphericity, args=(inPoints, 1, sphericity_queue, tree,))\n",
    "    sphericity_values.start()\n",
    "\n",
    "    sphericity_queue3 = Queue()\n",
    "    sphericity_values3 = Process(target=calculate_sphericity, args=(inPoints, 3, sphericity_queue3, tree,))\n",
    "    sphericity_values3.start()\n",
    "\n",
    "    sphericity_queue10 = Queue()\n",
    "    sphericity_values10 = Process(target=calculate_sphericity, args=(inPoints, 10, sphericity_queue10, tree,))\n",
    "    sphericity_values10.start()\n",
    "\n",
    "    anisotropy_queue = Queue() \n",
    "    anisotropy_values = Process(target=calculate_anisotropy, args=(inPoints, 1, anisotropy_queue, tree,))\n",
    "    anisotropy_values.start()\n",
    "\n",
    "    anisotropy_queue3 = Queue() \n",
    "    anisotropy_values3 = Process(target=calculate_anisotropy, args=(inPoints, 3, anisotropy_queue3, tree,))\n",
    "    anisotropy_values3.start()\n",
    "\n",
    "    anisotropy_queue10 = Queue() \n",
    "    anisotropy_values10 = Process(target=calculate_anisotropy, args=(inPoints, 10, anisotropy_queue10, tree,))\n",
    "    anisotropy_values10.start()\n",
    "\n",
    "    surface_variation_queue = Queue()\n",
    "    surface_variation_values = Process(target=calculate_surface_variation, args=(inPoints, 1, surface_variation_queue, tree,))\n",
    "    surface_variation_values.start()\n",
    "\n",
    "    surface_variation_queue3 = Queue()\n",
    "    surface_variation_values3 = Process(target=calculate_surface_variation, args=(inPoints, 3, surface_variation_queue3, tree,))\n",
    "    surface_variation_values3.start()\n",
    "\n",
    "    surface_variation_queue10 = Queue()\n",
    "    surface_variation_values10 = Process(target=calculate_surface_variation, args=(inPoints, 10, surface_variation_queue10, tree,))\n",
    "    surface_variation_values10.start()\n",
    "\n",
    "    curvature_queue = Queue()\n",
    "    curvature_values = Process(target=calculate_curvature, args=(inPoints, 1, curvature_queue, tree,))\n",
    "    curvature_values.start()\n",
    "\n",
    "    curvature_queue3 = Queue()\n",
    "    curvature_values3 = Process(target=calculate_curvature, args=(inPoints, 3, curvature_queue3, tree,))\n",
    "    curvature_values3.start()\n",
    "\n",
    "    curvature_queue10 = Queue()\n",
    "    curvature_values10 = Process(target=calculate_curvature, args=(inPoints, 10, curvature_queue10, tree,))\n",
    "    curvature_values10.start()\n",
    "\n",
    "    omnivariance_queue = Queue()\n",
    "    omnivariance_values =  Process(target=calculate_omnivariance, args=(inPoints, 1, omnivariance_queue, tree,))\n",
    "    omnivariance_values.start()\n",
    "\n",
    "    omnivariance_queue3 = Queue()\n",
    "    omnivariance_values3 =  Process(target=calculate_omnivariance, args=(inPoints, 3, omnivariance_queue3, tree,))\n",
    "    omnivariance_values3.start()\n",
    "\n",
    "    omnivariance_queue10 = Queue()\n",
    "    omnivariance_values10 =  Process(target=calculate_omnivariance, args=(inPoints, 10, omnivariance_queue10, tree,))\n",
    "    omnivariance_values10.start()\n",
    "\n",
    "    linearity_queue = Queue()\n",
    "    linearity_values =  Process(target=calculate_linearity, args=(inPoints, 1, linearity_queue, tree,))\n",
    "    linearity_values.start()\n",
    "\n",
    "    linearity_queue3 = Queue()\n",
    "    linearity_values3 =  Process(target=calculate_linearity, args=(inPoints, 3, linearity_queue3, tree,))\n",
    "    linearity_values3.start()\n",
    "\n",
    "    linearity_queue10 = Queue()\n",
    "    linearity_values10 =  Process(target=calculate_linearity, args=(inPoints, 10, linearity_queue10, tree,))\n",
    "    linearity_values10.start()\n",
    "\n",
    "    planarity_result = planarity_queue.get()\n",
    "    planarity_result3 = planarity_queue3.get()\n",
    "    planarity_result10 = planarity_queue10.get()\n",
    "\n",
    "    verticality_result = verticality_queue.get()\n",
    "    verticality_result3 = verticality_queue3.get()\n",
    "    verticality_result10 = verticality_queue10.get()\n",
    "\n",
    "    sphericity_result = sphericity_queue.get()\n",
    "    sphericity_result3 = sphericity_queue3.get()\n",
    "    sphericity_result10 = sphericity_queue10.get()\n",
    "\n",
    "    anisotropy_result = anisotropy_queue.get()\n",
    "    anisotropy_result3 = anisotropy_queue3.get()\n",
    "    anisotropy_result10 = anisotropy_queue10.get()\n",
    "\n",
    "    surface_variation_result = surface_variation_queue.get()\n",
    "    surface_variation_result3 = surface_variation_queue3.get()\n",
    "    surface_variation_result10 = surface_variation_queue10.get()\n",
    "\n",
    "    curvature_result = curvature_queue.get()\n",
    "    curvature_result3 = curvature_queue3.get()\n",
    "    curvature_result10 = curvature_queue10.get()\n",
    "\n",
    "    omnivariance_result = omnivariance_queue.get()\n",
    "    omnivariance_result3 = omnivariance_queue3.get()\n",
    "    omnivariance_result10 = omnivariance_queue10.get()\n",
    "\n",
    "    linearity_result = linearity_queue.get()\n",
    "    linearity_result3 = linearity_queue3.get()\n",
    "    linearity_result10 = linearity_queue10.get()\n",
    "\n",
    "    planarity_values.join()\n",
    "    planarity_values3.join()\n",
    "    planarity_values10.join()\n",
    "\n",
    "    verticality_values.join()\n",
    "    verticality_values3.join()\n",
    "    verticality_values10.join()\n",
    "\n",
    "    sphericity_values.join()\n",
    "    sphericity_values3.join()\n",
    "    sphericity_values10.join()\n",
    "\n",
    "    anisotropy_values.join()\n",
    "    anisotropy_values3.join()\n",
    "    anisotropy_values10.join()\n",
    "\n",
    "    surface_variation_values.join()\n",
    "    surface_variation_values3.join()\n",
    "    surface_variation_values10.join()\n",
    "\n",
    "    curvature_values.join()\n",
    "    curvature_values3.join()\n",
    "    curvature_values10.join()\n",
    "\n",
    "    omnivariance_values.join()\n",
    "    omnivariance_values3.join()\n",
    "    omnivariance_values10.join()\n",
    "\n",
    "    linearity_values.join()\n",
    "    linearity_values3.join()\n",
    "    linearity_values10.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c03d83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b59fc102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot with a color ramp based on verticality values\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "cmap = plt.get_cmap('viridis')\n",
    "sc = ax.scatter3D(inPoints[:, 0], inPoints[:, 1], inPoints[:, 2], c= omnivariance_result, cmap=cmap, s=1)\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "\n",
    "# Add a colorbar to show the scale of verticality values|\n",
    "cbar = plt.colorbar(sc, ax=ax)\n",
    "cbar.set_label('lidar')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac3831e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_dataframe(features, classification_codes, feature_names):\n",
    "    \"\"\"\n",
    "    params: All the calculated features from the 3d point cloud as a list.\n",
    "    params: The classification code extracted from the lidar_data.\n",
    "    params: Features name for the dataframe.\n",
    "    output: All the features are stacked in a dataframe.\n",
    "    \"\"\"\n",
    "    combined_features = np.column_stack(features)\n",
    "    \n",
    "    feature_df = pd.DataFrame(combined_features, columns=feature_names)\n",
    "    \n",
    "    feature_df['classification'] = classification_codes    \n",
    "    return feature_df\n",
    "\n",
    "# List of calculated feature arrays\n",
    "features = [planar_result, planar_result3, planar_result10, vertical_result, vertical_result3, vertical_result10,\n",
    "            sphere_result, sphere_result3, sphere_result10, anis_result, anis_result3, anis_result10,\n",
    "            variation_result, variation_result3, variation_result10, curv_result, curv_result3, curv_result10, \n",
    "            omni_result, omni_result3, omni_result10, linear_result, linear_result3, linear_result10]\n",
    "\n",
    "# List of feature names corresponding to the feature arrays\n",
    "feature_names = ['planarity','planarity3','planarity10','verticality', 'verticality3', 'verticality10', \n",
    "                 'sphericity','sphericity3','sphericity10', 'anisotropy','anisotropy3','anisotropy10',\n",
    "                 'surfaceVariation', 'surfaceVariation3', 'surfaceVariation10','curvature_values', 'curvature_values3', 'curvature_values10',\n",
    "                 'omnivariance', 'omnivariance3', 'omnivariance10', 'linearity', 'linearity3', 'linearity10']\n",
    "\n",
    "\n",
    "classification_codes = input_Data.classification\n",
    "feature_dataframe = create_feature_dataframe(features, classification_codes, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317e2d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing values (NaN)\n",
    "feature_dataframe = feature_dataframe.dropna()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = feature_dataframe.drop('classification', axis=1)\n",
    "y = feature_dataframe['classification']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the Random Forest classifier\n",
    "#clf = RandomForestClassifier(n_estimators=100, n_jobs= -1, random_state=42)\n",
    "#clf.fit(X_train, y_train)\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=400, learning_rate=0.1, \n",
    "                                    max_depth=14, max_features='log2', min_samples_split=2, \n",
    "                                    min_samples_leaf=1, random_state=42, verbose=1)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gb_clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c09993",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = gb_clf.feature_importances_\n",
    "print(importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9513f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = \"M:\\\\lidar\\\\RandomForest\\\\model\\\\9_knn_optimal_gb_classifier_model.pkl\"\n",
    "with open(model_filename, \"wb\") as file:\n",
    "    pickle.dump(gb_clf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72fa269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model from the file\n",
    "import pickle\n",
    "model_filename = \"M:\\\\lidar\\\\RandomForest\\\\model\\\\9_knn_optimal_gb_classifier_model.pkl\"\n",
    "with open(model_filename, \"rb\") as file:\n",
    "    loaded_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb3e333",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classify the lidar data first time\n",
    "def first_classify(initial_las):\n",
    "    output_file = initial_las\n",
    "    intial_classify = laspy.read(output_file)\n",
    "    initial_lidar_points = np.vstack((intial_classify.x, intial_classify.y, \n",
    "                                      intial_classify.z)).T\n",
    "    tree = KDTree(initial_lidar_points)\n",
    "    return intial_classify, initial_lidar_points, tree\n",
    "\n",
    "#Iteration of the first classified data\n",
    "def iter_classify(iteration_las):\n",
    "    output_file = iteration_las\n",
    "    iteration_data = laspy.read(output_file)\n",
    "    classification_filter = iteration_data.classification == 5\n",
    "    filtered_points = iteration_data.points[classification_filter]\n",
    "    iteration_lidar_points = np.vstack((filtered_points.x, filtered_points.y, \n",
    "                                        filtered_points.z)).T\n",
    "    \n",
    "    return iteration_lidar_points,classification_filter\n",
    "\n",
    "\n",
    "# Load LiDAR data (assuming LAS file format)\n",
    "output_file = \"M:\\\\lidar\\\\RandomForest\\\\Training_data\\\\Normalized\\\\anHavel.laz\"\n",
    "\n",
    "# for the first time classification\n",
    "intial_classify, lidar_points, ktree = first_classify(output_file)\n",
    "\n",
    "# for the iteration classification of the data\n",
    "#lidar_points,classification_filter = iter_classify(output_file)\n",
    "\n",
    "from lidar_function import calculate_planarity, calculate_verticality, calculate_sphericity, calculate_anisotropy, calculate_surface_variation\n",
    "from lidar_function import calculate_curvature, calculate_omnivariance, calculate_linearity\n",
    "from multiprocessing import Process, Queue\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    plan_queue = Queue()\n",
    "    new_feature1 = Process(target=calculate_planarity, args=(lidar_points, 1, plan_queue, ktree,))\n",
    "    new_feature1.start()\n",
    "\n",
    "    plan_queue2= Queue()\n",
    "    plan_feature2 = Process(target=calculate_planarity, args=(lidar_points, 3, plan_queue2, ktree,))\n",
    "    plan_feature2.start()\n",
    "\n",
    "    plan_queue3 = Queue()\n",
    "    plan_feature3 = Process(target=calculate_planarity, args=(lidar_points, 10, plan_queue3, ktree,))\n",
    "    plan_feature3.start()\n",
    "\n",
    "    vertical_queue = Queue()\n",
    "    new_feature2 = Process(target=calculate_verticality, args=(lidar_points, 1, vertical_queue, ktree,))\n",
    "    new_feature2.start()\n",
    "\n",
    "    vertical_queue2 = Queue()\n",
    "    vertical_feature2 = Process(target=calculate_verticality, args=(lidar_points, 3, vertical_queue2, ktree,))\n",
    "    vertical_feature2.start()\n",
    "\n",
    "    vertical_queue3 = Queue()\n",
    "    vertical_feature3 = Process(target=calculate_verticality, args=(lidar_points, 10, vertical_queue3, ktree,))\n",
    "    vertical_feature3.start()\n",
    "\n",
    "    sphere_queue = Queue()\n",
    "    new_feature3 = Process(target=calculate_sphericity, args=(lidar_points, 1, sphere_queue, ktree,))\n",
    "    new_feature3.start()\n",
    "\n",
    "    sphere_queue2 = Queue()\n",
    "    sphere_feature3 = Process(target=calculate_sphericity, args=(lidar_points, 3, sphere_queue2, ktree,))\n",
    "    sphere_feature3.start()\n",
    "\n",
    "    sphere_queue3 = Queue()\n",
    "    sphere_feature10 = Process(target=calculate_sphericity, args=(lidar_points, 10, sphere_queue3, ktree,))\n",
    "    sphere_feature10.start()\n",
    "\n",
    "    anisot_queue = Queue() \n",
    "    new_feature4 = Process(target=calculate_anisotropy, args=(lidar_points, 1, anisot_queue, ktree,))\n",
    "    new_feature4.start()\n",
    "\n",
    "    anisot_queue2 = Queue() \n",
    "    anisot_feature3 = Process(target=calculate_anisotropy, args=(lidar_points, 3, anisot_queue2, ktree,))\n",
    "    anisot_feature3.start()\n",
    "\n",
    "    anisot_queue3 = Queue() \n",
    "    anisot_feature10 = Process(target=calculate_anisotropy, args=(lidar_points, 10, anisot_queue3, ktree,))\n",
    "    anisot_feature10.start()\n",
    "\n",
    "    surface_queue = Queue()\n",
    "    new_feature5 = Process(target=calculate_surface_variation, args=(lidar_points, 1, surface_queue, ktree,))\n",
    "    new_feature5.start()\n",
    "\n",
    "    surface_queue2 = Queue()\n",
    "    variation_feature3 = Process(target=calculate_surface_variation, args=(lidar_points, 3, surface_queue2, ktree,))\n",
    "    variation_feature3.start()\n",
    "\n",
    "    surface_queue3 = Queue()\n",
    "    variation_feature10 = Process(target=calculate_surface_variation, args=(lidar_points, 10, surface_queue3, ktree,))\n",
    "    variation_feature10.start()\n",
    "\n",
    "    curve_queue = Queue()\n",
    "    new_feature6 = Process(target=calculate_curvature, args=(lidar_points, 1, curve_queue, ktree,))\n",
    "    new_feature6.start()\n",
    "\n",
    "    curve_queue2 = Queue()\n",
    "    curve_feature3 = Process(target=calculate_curvature, args=(lidar_points, 3, curve_queue2, ktree,))\n",
    "    curve_feature3.start()\n",
    "\n",
    "    curve_queue3 = Queue()\n",
    "    curve_feature10 = Process(target=calculate_curvature, args=(lidar_points, 10, curve_queue3, ktree,))\n",
    "    curve_feature10.start()\n",
    "\n",
    "    omni_queue = Queue()\n",
    "    new_feature7 =  Process(target=calculate_omnivariance, args=(lidar_points, 1, omni_queue, ktree,))\n",
    "    new_feature7.start()\n",
    "\n",
    "    omni_queue2 = Queue()\n",
    "    omni_feature3 =  Process(target=calculate_omnivariance, args=(lidar_points, 3, omni_queue2, ktree,))\n",
    "    omni_feature3.start()\n",
    "\n",
    "    omni_queue3 = Queue()\n",
    "    omni_feature10 =  Process(target=calculate_omnivariance, args=(lidar_points, 10, omni_queue3, ktree,))\n",
    "    omni_feature10.start()\n",
    "\n",
    "    linear_queue = Queue()\n",
    "    new_feature8 =  Process(target=calculate_linearity, args=(lidar_points, 1, linear_queue, ktree,))\n",
    "    new_feature8.start()\n",
    "    \n",
    "    linear_queue2 = Queue()\n",
    "    linear_feature3 =  Process(target=calculate_linearity, args=(lidar_points, 3, linear_queue2, ktree,))\n",
    "    linear_feature3.start()\n",
    "    \n",
    "    linear_queue3 = Queue()\n",
    "    linear_feature10 =  Process(target=calculate_linearity, args=(lidar_points, 10, linear_queue3, ktree,))\n",
    "    linear_feature10.start()\n",
    "\n",
    "    plan_result = plan_queue.get()\n",
    "    plan_result3 = plan_queue2.get()\n",
    "    plan_result10 = plan_queue3.get()\n",
    "    \n",
    "    vertical_result = vertical_queue.get()\n",
    "    vertical_result3 = vertical_queue2.get()\n",
    "    vertical_result10 = vertical_queue3.get()\n",
    "    \n",
    "    sphere_result = sphere_queue.get()\n",
    "    sphere_result3 = sphere_queue2.get()\n",
    "    sphere_result10 = sphere_queue3.get()\n",
    "    \n",
    "    anisot_result = anisot_queue.get()\n",
    "    anisot_result3 = anisot_queue2.get()\n",
    "    anisot_result10 = anisot_queue3.get()\n",
    "    \n",
    "    surface_result = surface_queue.get()\n",
    "    surface_result3 = surface_queue2.get()\n",
    "    surface_result10 = surface_queue3.get()\n",
    "    \n",
    "    curve_result = curve_queue.get()\n",
    "    curve_result3 = curve_queue2.get()\n",
    "    curve_result10 = curve_queue3.get()\n",
    "    \n",
    "    omni_result = omni_queue.get()\n",
    "    omni_result3 = omni_queue2.get()\n",
    "    omni_result10 = omni_queue3.get()\n",
    "    \n",
    "    linear_result = linear_queue.get()\n",
    "    linear_result3 = linear_queue2.get()\n",
    "    linear_result10 = linear_queue3.get()\n",
    "\n",
    "    new_feature1.join()\n",
    "    plan_feature2.join()\n",
    "    plan_feature3.join()\n",
    "    \n",
    "    new_feature2.join()\n",
    "    vertical_feature2.join()\n",
    "    vertical_feature3.join()\n",
    "    \n",
    "    new_feature3.join()\n",
    "    sphere_feature3.join()\n",
    "    sphere_feature10.join()\n",
    "    \n",
    "    new_feature4.join()\n",
    "    anisot_feature3.join()\n",
    "    anisot_feature10.join()\n",
    "    \n",
    "    new_feature5.join()\n",
    "    variation_feature3.join()\n",
    "    variation_feature10.join()\n",
    "    \n",
    "    new_feature6.join()\n",
    "    curve_feature3.join()\n",
    "    curve_feature10.join()\n",
    "    \n",
    "    new_feature7.join()\n",
    "    omni_feature3.join()\n",
    "    omni_feature10.join()\n",
    "    \n",
    "    new_feature8.join()\n",
    "    linear_feature3.join()\n",
    "    linear_feature10.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c17e1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix  = np.column_stack(( plan_result, plan_result3, plan_result10, vertical_result, vertical_result3, vertical_result10, \n",
    "                                   sphere_result, sphere_result3, sphere_result10, anisot_result,  anisot_result3, anisot_result10,\n",
    "                                    surface_result, surface_result3, surface_result10, curve_result, curve_result3, curve_result10,\n",
    "                                    omni_result, omni_result3, omni_result10, linear_result, linear_result3, linear_result10))\n",
    "\n",
    "feature_matrix = np.where(np.isinf(feature_matrix), np.nan , feature_matrix)\n",
    "\n",
    "imputer = SimpleImputer(strategy = \"mean\")\n",
    "\n",
    "feature_matrix_clean = imputer.fit_transform(feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9647d00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_predict(matrix, output_path, las, classification_filter=None):\n",
    "    lidar_data = laspy.read(las)\n",
    "    \n",
    "    # Use the loaded model to make predictions\n",
    "    loaded_y_pred = gb_clf.predict(matrix)\n",
    "\n",
    "    if classification_filter is not None:\n",
    "        lidar_data.classification[classification_filter] = loaded_y_pred.astype(np.uint8)\n",
    "    else:\n",
    "        lidar_data.classification = loaded_y_pred.astype(np.uint8)\n",
    "\n",
    "    # Preserving class 2 as in original data\n",
    "    \n",
    "\n",
    "    output_las_file = output_path\n",
    "    lidar_data.write(output_las_file)\n",
    "\n",
    "    return \"Data created\"\n",
    "\n",
    "def iteration_predict(matrix, output, las, classification_filter):\n",
    "    \n",
    "    lidar_data = laspy.read(las)\n",
    "    \n",
    "    # Create a new LAS data\n",
    "    new_lidar_data = laspy.create(point_format=lidar_data.point_format)\n",
    "\n",
    "    # Copy over the points from the original file\n",
    "    new_lidar_data.points = lidar_data.points.copy()\n",
    "\n",
    "    # Copy over the header\n",
    "    new_lidar = laspy.LasData(lidar_data.header)\n",
    "    \n",
    "    #predict the classification\n",
    "    loaded_y_pred = loaded_model.predict(matrix)\n",
    "\n",
    "    # Update the classification for the filtered points\n",
    "    new_lidar_data.classification[classification_filter] = loaded_y_pred.astype(np.uint8)\n",
    "\n",
    "    # Write the new LiDAR data to a .las file\n",
    "    new_lidar_data.write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b079af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_path = \"M:\\\\lidar\\\\RandomForest\\\\classified_data\\\\Normalized\\\\anderhavel_9knn.laz\"\n",
    "\n",
    "initial_predict(feature_matrix_clean,output_path,output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93eda07b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
